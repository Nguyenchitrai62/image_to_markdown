import cv2
import numpy as np
from paddleocr import PaddleOCR
import json
import os
from typing import List, Dict, Tuple, Any
from PIL import Image, ImageDraw, ImageFont
from googletrans import Translator
import time

# Import XY-Cut functions (gi·∫£ s·ª≠ ƒë√£ c√≥)
from xycut import recursive_xy_cut, points_to_bbox

def calculate_iou(box1, box2):
    """
    T√≠nh IoU (Intersection over Union) gi·ªØa hai bounding box
    
    Args:
        box1, box2: [x_min, y_min, x_max, y_max] format
        
    Returns:
        float: IoU value (0-1)
    """
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    
    if x1 >= x2 or y1 >= y2:
        return 0.0
    
    intersection = (x2 - x1) * (y2 - y1)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union = area1 + area2 - intersection
    
    return intersection / union if union > 0 else 0.0

def calculate_overlap_ratio(box1, box2):
    """
    T√≠nh t·ª∑ l·ªá overlap c·ªßa box nh·ªè h∆°n so v·ªõi box l·ªõn h∆°n
    
    Args:
        box1, box2: [x_min, y_min, x_max, y_max] format
        
    Returns:
        float: Overlap ratio (0-1)
    """
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    
    if x1 >= x2 or y1 >= y2:
        return 0.0
    
    intersection = (x2 - x1) * (y2 - y1)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    
    # T·ª∑ l·ªá overlap c·ªßa box nh·ªè h∆°n
    min_area = min(area1, area2)
    return intersection / min_area if min_area > 0 else 0.0

def has_intersection(box1, box2):
    """
    Ki·ªÉm tra hai bounding box c√≥ giao nhau kh√¥ng (d√π ch·ªâ 1 pixel)
    
    Args:
        box1, box2: [x_min, y_min, x_max, y_max] format
        
    Returns:
        bool: True n·∫øu c√≥ giao nhau, False n·∫øu kh√¥ng
    """
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    
    # C√≥ giao nhau n·∫øu x1 < x2 v√† y1 < y2
    return x1 < x2 and y1 < y2

def convert_bbox_to_xycut_format(bbox):
    """
    Chuy·ªÉn ƒë·ªïi bbox t·ª´ PaddleOCR format sang [x_min, y_min, x_max, y_max]
    """
    try:
        if isinstance(bbox, list) and len(bbox) == 4:
            if isinstance(bbox[0], list):
                # Format: [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
                x_coords = [point[0] for point in bbox]
                y_coords = [point[1] for point in bbox]
                result = [min(x_coords), min(y_coords), max(x_coords), max(y_coords)]
            else:
                # Format: [x1, y1, x2, y2]
                result = bbox
        elif hasattr(bbox, 'shape') and len(bbox.shape) == 2:
            # Numpy array shape (4, 2)
            x_coords = bbox[:, 0]
            y_coords = bbox[:, 1]
            result = [np.min(x_coords), np.min(y_coords), np.max(x_coords), np.max(y_coords)]
        else:
            # Fallback - convert to numpy and try again
            bbox_array = np.array(bbox)
            if bbox_array.shape == (4, 2):
                x_coords = bbox_array[:, 0]
                y_coords = bbox_array[:, 1]
                result = [np.min(x_coords), np.min(y_coords), np.max(x_coords), np.max(y_coords)]
            elif len(bbox_array) == 8:
                # Format: [x1,y1,x2,y2,x3,y3,x4,y4]
                result = points_to_bbox(bbox_array)
            else:
                result = [0, 0, 100, 100]
        
        # ƒê·∫£m b·∫£o t·∫•t c·∫£ gi√° tr·ªã l√† integers v√† >= 0
        result = [max(0, int(x)) for x in result]
        return result
        
    except Exception:
        return [0, 0, 100, 100]

def find_overlapping_groups(text_infos):
    """
    T√¨m c√°c nh√≥m text boxes c√≥ ch·ªìng l√™n nhau (b·∫•t k·ª≥ m·ª©c ƒë·ªô n√†o)
    
    Args:
        text_infos: List of dict v·ªõi keys: 'text', 'confidence', 'bbox'
        
    Returns:
        List of lists: M·ªói sublist ch·ª©a indices c·ªßa c√°c box ch·ªìng l√™n nhau
    """
    n = len(text_infos)
    if n == 0:
        return []
    
    # Convert t·∫•t c·∫£ bbox v·ªÅ ƒë·ªãnh d·∫°ng chu·∫©n
    boxes = []
    for info in text_infos:
        bbox = convert_bbox_to_xycut_format(info['bbox'])
        boxes.append(bbox)
    
    # T·∫°o ma tr·∫≠n adjacency
    overlap_matrix = np.zeros((n, n), dtype=bool)
    
    for i in range(n):
        for j in range(i + 1, n):
            # Ch·ªâ c·∫ßn ki·ªÉm tra c√≥ giao nhau kh√¥ng (kh√¥ng c·∫ßn ng∆∞·ª°ng)
            if has_intersection(boxes[i], boxes[j]):
                overlap_matrix[i][j] = True
                overlap_matrix[j][i] = True
    
    # T√¨m c√°c connected components (nh√≥m c√°c box ch·ªìng l√™n nhau)
    visited = [False] * n
    groups = []
    
    def dfs(node, current_group):
        visited[node] = True
        current_group.append(node)
        
        for neighbor in range(n):
            if overlap_matrix[node][neighbor] and not visited[neighbor]:
                dfs(neighbor, current_group)
    
    for i in range(n):
        if not visited[i]:
            current_group = []
            dfs(i, current_group)
            groups.append(current_group)
    
    return groups

def merge_overlapping_boxes(text_infos, groups):
    """
    G·ªôp c√°c box overlap th√†nh box l·ªõn v√† s·∫Øp x·∫øp text b·∫±ng XY-Cut
    
    Args:
        text_infos: List of text info dicts
        groups: List of lists, m·ªói sublist ch·ª©a indices c·ªßa c√°c box c·∫ßn g·ªôp
        
    Returns:
        List of merged text info dicts
    """
    merged_results = []
    
    for group in groups:
        if len(group) == 1:
            # Ch·ªâ c√≥ 1 box, kh√¥ng c·∫ßn g·ªôp
            merged_results.append(text_infos[group[0]])
        else:
            # G·ªôp nhi·ªÅu box
            group_texts = []
            group_confidences = []
            all_bboxes = []
            
            # Collect th√¥ng tin c·ªßa t·∫•t c·∫£ box trong group
            for idx in group:
                info = text_infos[idx]
                group_texts.append({
                    'text': info['text'],
                    'confidence': info['confidence'],
                    'bbox': info['bbox']
                })
                group_confidences.append(info['confidence'])
                all_bboxes.append(convert_bbox_to_xycut_format(info['bbox']))
            
            # T√≠nh bounding box g·ªôp
            all_bboxes = np.array(all_bboxes)
            merged_bbox = [
                int(np.min(all_bboxes[:, 0])),  # x_min
                int(np.min(all_bboxes[:, 1])),  # y_min
                int(np.max(all_bboxes[:, 2])),  # x_max
                int(np.max(all_bboxes[:, 3]))   # y_max
            ]
            
            # S·∫Øp x·∫øp text trong group b·∫±ng XY-Cut
            sorted_group_texts = sort_texts_with_xycut(group_texts)
            
            # G·ªôp text v√† t√≠nh confidence trung b√¨nh
            combined_text = " ".join([t['text'] for t in sorted_group_texts])
            avg_confidence = np.mean(group_confidences)
            
            merged_info = {
                'text': combined_text,
                'confidence': float(avg_confidence),
                'bbox': merged_bbox,
                'is_merged': True,
                'merged_from_count': len(group),
                'original_texts': [t['text'] for t in sorted_group_texts]
            }
            
            merged_results.append(merged_info)
    
    return merged_results

def sort_texts_with_xycut(texts_with_info):
    """
    S·∫Øp x·∫øp text theo th·ª© t·ª± ƒë·ªçc s·ª≠ d·ª•ng XY-Cut algorithm
    """
    if not texts_with_info:
        return []
    
    # Chu·∫©n b·ªã d·ªØ li·ªáu cho XY-Cut
    boxes = []
    indices = list(range(len(texts_with_info)))
    
    for i, text_info in enumerate(texts_with_info):
        bbox = text_info.get('bbox', [[0, 0], [0, 0], [0, 0], [0, 0]])
        converted_bbox = convert_bbox_to_xycut_format(bbox)
        boxes.append(converted_bbox)
    
    boxes = np.array(boxes, dtype=np.int32)
    indices = np.array(indices, dtype=np.int32)
    
    if len(boxes) == 0:
        return []
    
    try:
        # Ch·∫°y XY-Cut ƒë·ªÉ l·∫•y th·ª© t·ª± ƒë·ªçc
        reading_order = []
        recursive_xy_cut(boxes, indices, reading_order)
        
        # S·∫Øp x·∫øp texts theo th·ª© t·ª± ƒë·ªçc
        if reading_order:
            sorted_texts = [texts_with_info[i] for i in reading_order]
        else:
            # Fallback v·ªÅ s·∫Øp x·∫øp ƒë∆°n gi·∫£n
            sorted_texts = sort_texts_by_position_fallback(texts_with_info)
            
    except Exception:
        # Fallback v·ªÅ s·∫Øp x·∫øp ƒë∆°n gi·∫£n
        sorted_texts = sort_texts_by_position_fallback(texts_with_info)
    
    return sorted_texts

def sort_texts_by_position_fallback(texts_with_info):
    """Fallback sorting method"""
    def get_sort_key(text_info):
        bbox = text_info.get('bbox', [[0, 0], [0, 0], [0, 0], [0, 0]])
        try:
            if isinstance(bbox[0], list):
                x_coords = [point[0] for point in bbox]
                y_coords = [point[1] for point in bbox]
                center_x = sum(x_coords) / len(x_coords)
                center_y = sum(y_coords) / len(y_coords)
            else:
                center_x, center_y = bbox[0], bbox[1]
            return (center_y, center_x)
        except:
            return (0, 0)
    
    return sorted(texts_with_info, key=get_sort_key)

def translate_text(text, src_lang="ja", dest_lang="vi", max_retries=3):
    """
    D·ªãch text s·ª≠ d·ª•ng Google Translate v·ªõi retry mechanism
    
    Args:
        text: Text c·∫ßn d·ªãch
        src_lang: Ng√¥n ng·ªØ ngu·ªìn
        dest_lang: Ng√¥n ng·ªØ ƒë√≠ch
        max_retries: S·ªë l·∫ßn th·ª≠ l·∫°i t·ªëi ƒëa
        
    Returns:
        str: Text ƒë√£ d·ªãch
    """
    if not text or not text.strip():
        return text
    
    translator = Translator()
    
    for attempt in range(max_retries):
        try:
            result = translator.translate(text, src=src_lang, dest=dest_lang)
            return result.text
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói d·ªãch l·∫ßn {attempt + 1}: {str(e)}")
            if attempt < max_retries - 1:
                time.sleep(1)  # ƒê·ª£i 1 gi√¢y tr∆∞·ªõc khi th·ª≠ l·∫°i
            else:
                print(f"‚ùå Kh√¥ng th·ªÉ d·ªãch text: '{text}', gi·ªØ nguy√™n text g·ªëc")
                return text
    
    return text

def get_optimal_font_size(text, bbox_width, bbox_height, font_path, min_size=12, max_size=60):
    """
    T√≠nh to√°n font size t·ªëi ∆∞u ƒë·ªÉ text v·ª´a v·ªõi bounding box
    
    Args:
        text: Text c·∫ßn v·∫Ω
        bbox_width: Chi·ªÅu r·ªông bbox
        bbox_height: Chi·ªÅu cao bbox
        font_path: ƒê∆∞·ªùng d·∫´n font
        min_size: Font size t·ªëi thi·ªÉu
        max_size: Font size t·ªëi ƒëa
        
    Returns:
        int: Font size t·ªëi ∆∞u
    """
    if not text:
        return min_size
    
    # Binary search ƒë·ªÉ t√¨m font size t·ªëi ∆∞u
    left, right = min_size, max_size
    optimal_size = min_size
    
    while left <= right:
        mid_size = (left + right) // 2
        try:
            font = ImageFont.truetype(font_path, mid_size)
            
            # T√≠nh k√≠ch th∆∞·ªõc text v·ªõi font size hi·ªán t·∫°i
            bbox = font.getbbox(text)
            text_width = bbox[2] - bbox[0]
            text_height = bbox[3] - bbox[1]
            
            # Ki·ªÉm tra text c√≥ v·ª´a trong bbox kh√¥ng (v·ªõi margin 10%)
            margin_width = bbox_width * 0.1
            margin_height = bbox_height * 0.1
            
            if (text_width <= bbox_width - margin_width and 
                text_height <= bbox_height - margin_height):
                optimal_size = mid_size
                left = mid_size + 1
            else:
                right = mid_size - 1
                
        except Exception:
            right = mid_size - 1
    
    return max(optimal_size, min_size)

def draw_text_on_image(image, text_infos_with_translation, font_path="C:/Windows/Fonts/times.ttf"):
    """
    V·∫Ω text ƒë√£ d·ªãch l√™n ·∫£nh v·ªõi n·ªÅn tr·∫Øng
    
    Args:
        image: PIL Image object
        text_infos_with_translation: List c√°c text info ƒë√£ c√≥ translation
        font_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn font
        
    Returns:
        PIL Image: ·∫¢nh ƒë√£ v·∫Ω text
    """
    img_with_text = image.copy()
    draw = ImageDraw.Draw(img_with_text)
    
    # Ki·ªÉm tra font c√≥ t·ªìn t·∫°i kh√¥ng
    if not os.path.exists(font_path):
        print(f"‚ö†Ô∏è Font kh√¥ng t·ªìn t·∫°i: {font_path}")
        print("S·ª≠ d·ª•ng font m·∫∑c ƒë·ªãnh")
        font_path = None
    
    for i, text_info in enumerate(text_infos_with_translation):
        try:
            bbox = text_info['bbox']
            translated_text = text_info.get('translated_text', text_info['text'])
            
            # Convert bbox
            if len(bbox) == 4 and not isinstance(bbox[0], list):
                x_min, y_min, x_max, y_max = bbox
            else:
                converted = convert_bbox_to_xycut_format(bbox)
                x_min, y_min, x_max, y_max = converted
            
            # T√≠nh k√≠ch th∆∞·ªõc bbox
            bbox_width = x_max - x_min
            bbox_height = y_max - y_min
            
            if bbox_width <= 0 or bbox_height <= 0:
                continue
            
            # V·∫Ω n·ªÅn tr·∫Øng
            draw.rectangle([x_min, y_min, x_max, y_max], fill='white', outline=None)
            
            # T√≠nh font size t·ªëi ∆∞u
            if font_path and os.path.exists(font_path):
                optimal_font_size = get_optimal_font_size(
                    translated_text, bbox_width, bbox_height, font_path
                )
                font = ImageFont.truetype(font_path, optimal_font_size)
            else:
                # S·ª≠ d·ª•ng font m·∫∑c ƒë·ªãnh n·∫øu kh√¥ng t√¨m th·∫•y font
                try:
                    font = ImageFont.load_default()
                except:
                    continue
            
            # T√≠nh v·ªã tr√≠ ƒë·ªÉ center text
            text_bbox = draw.textbbox((0, 0), translated_text, font=font)
            text_width = text_bbox[2] - text_bbox[0]
            text_height = text_bbox[3] - text_bbox[1]
            
            # Center text trong bbox
            text_x = x_min + (bbox_width - text_width) // 2
            text_y = y_min + (bbox_height - text_height) // 2
            
            # ƒê·∫£m b·∫£o text kh√¥ng v∆∞·ª£t ra ngo√†i bbox
            text_x = max(x_min, min(text_x, x_max - text_width))
            text_y = max(y_min, min(text_y, y_max - text_height))
            
            # V·∫Ω text
            draw.text((text_x, text_y), translated_text, fill='black', font=font)
            
            # V·∫Ω vi·ªÅn ƒë·ªÉ debug (t√πy ch·ªçn)
            if text_info.get('is_merged', False):
                draw.rectangle([x_min, y_min, x_max, y_max], outline='red', width=2)
            else:
                draw.rectangle([x_min, y_min, x_max, y_max], outline='blue', width=1)
                
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói v·∫Ω text {i}: {str(e)}")
            continue
    
    return img_with_text

def process_image_with_translation(image_input, 
                                   src_lang="ja",
                                   dest_lang="vi",
                                   output_json_path=None,
                                   save_debug_image=False,
                                   save_translated_image=True,
                                   font_path="C:/Windows/Fonts/times.ttf"):
    """
    Main function: X·ª≠ l√Ω ·∫£nh OCR, g·ªôp box, d·ªãch text v√† v·∫Ω l√™n ·∫£nh
    
    Args:
        image_input: ƒê∆∞·ªùng d·∫´n ·∫£nh ho·∫∑c numpy array
        src_lang: Ng√¥n ng·ªØ ngu·ªìn (m·∫∑c ƒë·ªãnh "ja")
        dest_lang: Ng√¥n ng·ªØ ƒë√≠ch (m·∫∑c ƒë·ªãnh "vi")
        output_json_path: ƒê∆∞·ªùng d·∫´n l∆∞u JSON
        save_debug_image: C√≥ l∆∞u ·∫£nh debug kh√¥ng
        save_translated_image: C√≥ l∆∞u ·∫£nh ƒë√£ d·ªãch kh√¥ng
        font_path: ƒê∆∞·ªùng d·∫´n font
        
    Returns:
        dict: K·∫øt qu·∫£ x·ª≠ l√Ω
    """
    # Kh·ªüi t·∫°o OCR
    ocr = PaddleOCR(
        use_doc_orientation_classify=False,
        use_doc_unwarping=False,
        use_textline_orientation=False,
        text_recognition_model_name="PP-OCRv5_server_rec",
        text_detection_model_name="PP-OCRv5_server_det",
    )
    
    # Ki·ªÉm tra input
    if isinstance(image_input, str):
        if not os.path.exists(image_input):
            raise FileNotFoundError(f"·∫¢nh kh√¥ng t·ªìn t·∫°i: {image_input}")
        input_data = image_input
        base_name = os.path.splitext(os.path.basename(image_input))[0]
        # Load ·∫£nh cho vi·ªác v·∫Ω
        original_image = Image.open(image_input)
    elif isinstance(image_input, np.ndarray):
        input_data = image_input
        base_name = "image_array"
        # Convert numpy array sang PIL Image
        if len(image_input.shape) == 3:
            original_image = Image.fromarray(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))
        else:
            original_image = Image.fromarray(image_input)
    else:
        raise TypeError("image_input ph·∫£i l√† ƒë∆∞·ªùng d·∫´n ho·∫∑c numpy array")
    
    # T·∫°o th∆∞ m·ª•c output
    output_dir = "./output"
    os.makedirs(output_dir, exist_ok=True)
    
    # Ch·∫°y OCR
    print("üîç ƒêang ch·∫°y OCR...")
    result = ocr.predict(input=input_data)
    
    # Extract text information
    all_texts_with_info = []
    for res in result:
        texts = res.get("rec_texts", [])
        scores = res.get("rec_scores", [])
        boxes = res.get("dt_polys", [])
        
        for text, score, box in zip(texts, scores, boxes):
            text_info = {
                'text': text,
                'confidence': float(score),
                'bbox': box.tolist() if hasattr(box, 'tolist') else box
            }
            all_texts_with_info.append(text_info)
    
    print(f"üìä T√¨m th·∫•y {len(all_texts_with_info)} text boxes ban ƒë·∫ßu")
    
    # T√¨m v√† g·ªôp c√°c box ch·ªìng l√™n nhau
    print("üîÑ ƒêang g·ªôp c√°c box ch·ªìng l√™n nhau...")
    overlapping_groups = find_overlapping_groups(all_texts_with_info)
    merged_texts = merge_overlapping_boxes(all_texts_with_info, overlapping_groups)
    
    # S·∫Øp x·∫øp to√†n b·ªô k·∫øt qu·∫£ theo XY-Cut
    print("üìù ƒêang s·∫Øp x·∫øp text theo th·ª© t·ª± ƒë·ªçc...")
    final_sorted_texts = sort_texts_with_xycut(merged_texts)
    
    # D·ªãch text
    print(f"üåç ƒêang d·ªãch text t·ª´ {src_lang} sang {dest_lang}...")
    for i, text_info in enumerate(final_sorted_texts):
        original_text = text_info['text']
        print(f"ƒêang d·ªãch {i+1}/{len(final_sorted_texts)}: {original_text[:50]}...")
        
        translated_text = translate_text(original_text, src_lang, dest_lang)
        text_info['translated_text'] = translated_text
        text_info['original_text'] = original_text
        text_info['src_lang'] = src_lang
        text_info['dest_lang'] = dest_lang
        
        # time.sleep(0.1)  # Tr√°nh spam API
    
    print("‚úÖ Ho√†n th√†nh d·ªãch text")
    
    # Th·ªëng k√™
    merged_count = sum(1 for group in overlapping_groups if len(group) > 1)
    total_merged_boxes = sum(len(group) for group in overlapping_groups if len(group) > 1)
    
    print(f"üìà K·∫øt qu·∫£ g·ªôp box:")
    print(f"- Box ban ƒë·∫ßu: {len(all_texts_with_info)}")
    print(f"- Nh√≥m g·ªôp: {merged_count}")
    print(f"- Box cu·ªëi c√πng: {len(final_sorted_texts)}")
    
    # Chu·∫©n b·ªã output data
    output_data = {
        'metadata': {
            'total_original_boxes': len(all_texts_with_info),
            'total_merged_groups': merged_count,
            'total_final_boxes': len(final_sorted_texts),
            'source_language': src_lang,
            'target_language': dest_lang,
            'processing_timestamp': __import__('datetime').datetime.now().isoformat()
        },
        'texts': []
    }
    
    # Add text data
    for i, text_info in enumerate(final_sorted_texts):
        text_data = {
            'index': i,
            'original_text': text_info['original_text'],
            'translated_text': text_info['translated_text'],
            'confidence': text_info['confidence'],
            'bbox': text_info['bbox'],
            'is_merged': text_info.get('is_merged', False)
        }
        
        if text_info.get('is_merged', False):
            text_data['merged_from_count'] = text_info['merged_from_count']
            text_data['original_texts'] = text_info['original_texts']
        
        output_data['texts'].append(text_data)
    
    # Combined text (c·∫£ g·ªëc v√† d·ªãch)
    output_data['combined_original_text'] = " ".join([t['original_text'] for t in final_sorted_texts])
    output_data['combined_translated_text'] = " ".join([t['translated_text'] for t in final_sorted_texts])
    
    # L∆∞u JSON
    if output_json_path is None:
        output_json_path = os.path.join(output_dir, f"{base_name}_translated_ocr_result.json")
    else:
        output_json_path = os.path.join(output_dir, output_json_path)
    
    with open(output_json_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print(f"üíæ ƒê√£ l∆∞u k·∫øt qu·∫£ JSON v√†o: {output_json_path}")
    
    # V·∫Ω text d·ªãch l√™n ·∫£nh
    if save_translated_image:
        print("üé® ƒêang v·∫Ω text d·ªãch l√™n ·∫£nh...")
        translated_image = draw_text_on_image(original_image, final_sorted_texts, font_path)
        
        # L∆∞u ·∫£nh ƒë√£ d·ªãch
        translated_image_path = os.path.join(output_dir, f"{base_name}_translated.jpg")
        translated_image.save(translated_image_path, quality=95)
        print(f"üñºÔ∏è ƒê√£ l∆∞u ·∫£nh d·ªãch v√†o: {translated_image_path}")
    
    # L∆∞u ·∫£nh debug n·∫øu c·∫ßn
    if save_debug_image and isinstance(image_input, str):
        debug_image_path = os.path.join(output_dir, f"{base_name}_debug_boxes.jpg")
        save_debug_visualization(image_input, final_sorted_texts, debug_image_path)
        print(f"üñºÔ∏è ƒê√£ l∆∞u ·∫£nh debug v√†o: {debug_image_path}")
    
    return output_data

def save_debug_visualization(image_path, text_infos, output_path):
    """L∆∞u ·∫£nh visualization ƒë·ªÉ debug"""
    img = cv2.imread(image_path)
    if img is None:
        return
    
    # V·∫Ω bounding boxes
    for i, text_info in enumerate(text_infos):
        bbox = text_info['bbox']
        
        # Convert bbox to rectangle points
        if len(bbox) == 4 and not isinstance(bbox[0], list):
            # Format [x_min, y_min, x_max, y_max]
            x1, y1, x2, y2 = bbox
            pts = np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2]], np.int32)
        else:
            # Other formats
            converted = convert_bbox_to_xycut_format(bbox)
            x1, y1, x2, y2 = converted
            pts = np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2]], np.int32)
        
        # Ch·ªçn m√†u: ƒë·ªè cho merged box, xanh cho single box
        color = (0, 0, 255) if text_info.get('is_merged', False) else (0, 255, 0)
        thickness = 3 if text_info.get('is_merged', False) else 2
        
        cv2.polylines(img, [pts], True, color, thickness)
        
        # V·∫Ω s·ªë th·ª© t·ª±
        cv2.putText(img, str(i), (int(x1), int(y1)-10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
    
    cv2.imwrite(output_path, img)

# Test function
def test_ocr_translation():
    """Test function v·ªõi d·ªãch thu·∫≠t"""
    image_path = "./cropped_boxes/Chap189-Page011.jpg"  # Thay ƒë·ªïi path n√†y
    
    if os.path.exists(image_path):
        print("=== TEST OCR + TRANSLATION + TEXT OVERLAY ===")
        
        # Test d·ªãch t·ª´ ti·∫øng Nh·∫≠t sang ti·∫øng Vi·ªát
        print("\nüáØüáµ‚û°Ô∏èüáªüá≥ X·ª≠ l√Ω ·∫£nh: Nh·∫≠t ‚Üí Vi·ªát")
        result = process_image_with_translation(
            image_path,
            src_lang="ja",
            dest_lang="vi", 
            output_json_path="translated_ja_to_vi.json",
            save_debug_image=True,
            save_translated_image=True,
            font_path="C:/Windows/Fonts/times.ttf"  # Ho·∫∑c arial.ttf
        )
        
        print(f"\nüìà K·∫øt qu·∫£:")
        print(f"- Box ban ƒë·∫ßu: {result['metadata']['total_original_boxes']}")
        print(f"- Nh√≥m g·ªôp: {result['metadata']['total_merged_groups']}")
        print(f"- Box cu·ªëi c√πng: {result['metadata']['total_final_boxes']}")
        
        print(f"\nüìù Text g·ªëc (Nh·∫≠t):")
        original_text = result['combined_original_text'][:200] + "..." if len(result['combined_original_text']) > 200 else result['combined_original_text']
        print(original_text)
        
        print(f"\nüìù Text d·ªãch (Vi·ªát):")
        translated_text = result['combined_translated_text'][:200] + "..." if len(result['combined_translated_text']) > 200 else result['combined_translated_text']
        print(translated_text)
        
        print(f"\nüíæ T·∫•t c·∫£ file output:")
        print(f"- JSON: ./output/translated_ja_to_vi.json")
        print(f"- ·∫¢nh d·ªãch: ./output/{os.path.splitext(os.path.basename(image_path))[0]}_translated.jpg")
        print(f"- ·∫¢nh debug: ./output/{os.path.splitext(os.path.basename(image_path))[0]}_debug_boxes.jpg")
        
        # In chi ti·∫øt v√†i text ƒë·∫ßu ti√™n
        print(f"\nüîç Chi ti·∫øt 3 text ƒë·∫ßu ti√™n:")
        for i, text_data in enumerate(result['texts'][:3]):
            print(f"{i+1}. G·ªëc: '{text_data['original_text']}'")
            print(f"   D·ªãch: '{text_data['translated_text']}'")
            print(f"   Confidence: {text_data['confidence']:.3f}")
            print(f"   Merged: {text_data['is_merged']}")
            print()
        
    else:
        print(f"‚ùå File {image_path} kh√¥ng t·ªìn t·∫°i")
        print("T·∫°o th∆∞ m·ª•c cropped_boxes/ v√† ƒë·∫∑t ·∫£nh test v√†o ƒë√≥")

def test_other_languages():
    """Test v·ªõi c√°c ng√¥n ng·ªØ kh√°c"""
    image_path = "./test_images/sample.jpg"  # Thay path ph√π h·ª£p
    
    if os.path.exists(image_path):
        print("=== TEST C√ÅC NG√îN NG·ªÆ KH√ÅC ===")
        
        # Test Trung ‚Üí Vi·ªát
        print("\nüá®üá≥‚û°Ô∏èüáªüá≥ Trung Qu·ªëc ‚Üí Vi·ªát Nam")
        process_image_with_translation(
            image_path,
            src_lang="zh",
            dest_lang="vi",
            output_json_path="translated_zh_to_vi.json"
        )
        
        # Test H√†n ‚Üí Vi·ªát  
        print("\nüá∞üá∑‚û°Ô∏èüáªüá≥ H√†n Qu·ªëc ‚Üí Vi·ªát Nam")
        process_image_with_translation(
            image_path,
            src_lang="ko", 
            dest_lang="vi",
            output_json_path="translated_ko_to_vi.json"
        )
        
        # Test Anh ‚Üí Vi·ªát
        print("\nüá∫üá∏‚û°Ô∏èüáªüá≥ Ti·∫øng Anh ‚Üí Vi·ªát Nam") 
        process_image_with_translation(
            image_path,
            src_lang="en",
            dest_lang="vi",
            output_json_path="translated_en_to_vi.json"
        )

def quick_translate_image(image_path, src_lang="ja", dest_lang="vi"):
    """
    H√†m nhanh ƒë·ªÉ d·ªãch ·∫£nh v·ªõi tham s·ªë t·ªëi thi·ªÉu
    
    Args:
        image_path: ƒê∆∞·ªùng d·∫´n ·∫£nh
        src_lang: Ng√¥n ng·ªØ ngu·ªìn
        dest_lang: Ng√¥n ng·ªØ ƒë√≠ch
        
    Returns:
        str: ƒê∆∞·ªùng d·∫´n ·∫£nh ƒë√£ d·ªãch
    """
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"·∫¢nh kh√¥ng t·ªìn t·∫°i: {image_path}")
    
    print(f"üöÄ D·ªãch nhanh: {src_lang} ‚Üí {dest_lang}")
    
    result = process_image_with_translation(
        image_path,
        src_lang=src_lang,
        dest_lang=dest_lang,
        save_debug_image=False,
        save_translated_image=True
    )
    
    base_name = os.path.splitext(os.path.basename(image_path))[0]
    translated_image_path = f"./output/{base_name}_translated.jpg"
    
    print(f"‚úÖ Ho√†n th√†nh! ·∫¢nh d·ªãch: {translated_image_path}")
    return translated_image_path

# C√°c h√†m ti·ªán √≠ch
def batch_translate_images(image_folder, src_lang="ja", dest_lang="vi"):
    """
    D·ªãch h√†ng lo·∫°t ·∫£nh trong folder
    
    Args:
        image_folder: ƒê∆∞·ªùng d·∫´n folder ch·ª©a ·∫£nh
        src_lang: Ng√¥n ng·ªØ ngu·ªìn  
        dest_lang: Ng√¥n ng·ªØ ƒë√≠ch
    """
    if not os.path.exists(image_folder):
        print(f"‚ùå Folder kh√¥ng t·ªìn t·∫°i: {image_folder}")
        return
    
    # T√¨m t·∫•t c·∫£ ·∫£nh trong folder
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
    image_files = []
    
    for file in os.listdir(image_folder):
        if any(file.lower().endswith(ext) for ext in image_extensions):
            image_files.append(os.path.join(image_folder, file))
    
    if not image_files:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh n√†o trong {image_folder}")
        return
    
    print(f"üìÅ T√¨m th·∫•y {len(image_files)} ·∫£nh ƒë·ªÉ d·ªãch")
    print(f"üåç D·ªãch t·ª´ {src_lang} sang {dest_lang}")
    
    successful = 0
    failed = 0
    
    for i, image_path in enumerate(image_files):
        try:
            print(f"\nüì∏ ƒêang x·ª≠ l√Ω {i+1}/{len(image_files)}: {os.path.basename(image_path)}")
            
            quick_translate_image(image_path, src_lang, dest_lang)
            successful += 1
            
        except Exception as e:
            print(f"‚ùå L·ªói x·ª≠ l√Ω {os.path.basename(image_path)}: {str(e)}")
            failed += 1
    
    print(f"\nüìä K·∫øt qu·∫£ batch translation:")
    print(f"‚úÖ Th√†nh c√¥ng: {successful}")
    print(f"‚ùå Th·∫•t b·∫°i: {failed}")
    print(f"üìÅ T·∫•t c·∫£ k·∫øt qu·∫£ trong folder: ./output/")

if __name__ == "__main__":
    # Ch·∫°y test c∆° b·∫£n
    test_ocr_translation()
    
    # Uncomment ƒë·ªÉ test c√°c ng√¥n ng·ªØ kh√°c
    # test_other_languages()
    
    # Uncomment ƒë·ªÉ test batch processing
    # batch_translate_images("./test_images/", "ja", "vi")