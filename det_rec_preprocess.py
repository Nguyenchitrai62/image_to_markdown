import cv2
import numpy as np
from paddleocr import PaddleOCR
import paddle
import os
import json

# Import XY-Cut functions
from xycut import recursive_xy_cut, points_to_bbox

# Global OCR instance - kh·ªüi t·∫°o m·ªôt l·∫ßn duy nh·∫•t
_ocr_instance = None

def get_ocr_instance():
    """L·∫•y OCR instance (singleton pattern)"""
    global _ocr_instance
    if _ocr_instance is None:
        _ocr_instance = PaddleOCR(
            use_doc_orientation_classify=False,
            use_doc_unwarping=False,
            use_textline_orientation=False,
            text_recognition_model_dir="./PP-OCRv5_server_rec_infer",
            text_recognition_model_name="PP-OCRv5_server_rec",
            text_detection_model_name="PP-OCRv5_server_det",
        )
    return _ocr_instance

def initialize_ocr():
    """Kh·ªüi t·∫°o PaddleOCR (deprecated - s·ª≠ d·ª•ng get_ocr_instance() thay th·∫ø)"""
    return get_ocr_instance()

def convert_bbox_to_xycut_format(bbox):
    """
    Chuy·ªÉn ƒë·ªïi bbox t·ª´ PaddleOCR format sang [x_min, y_min, x_max, y_max] cho XY-Cut
    
    Args:
        bbox: PaddleOCR bbox format - list of 4 points [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
    
    Returns:
        list: [x_min, y_min, x_max, y_max]
    """
    try:
        if isinstance(bbox, list) and len(bbox) == 4:
            if isinstance(bbox[0], list):
                # Format: [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]
                x_coords = [point[0] for point in bbox]
                y_coords = [point[1] for point in bbox]
                result = [min(x_coords), min(y_coords), max(x_coords), max(y_coords)]
            else:
                # Format: [x1, y1, x2, y2] - gi·∫£ s·ª≠ ƒë√¢y l√† min-max format
                result = bbox
        elif hasattr(bbox, 'shape') and len(bbox.shape) == 2:
            # Numpy array shape (4, 2)
            x_coords = bbox[:, 0]
            y_coords = bbox[:, 1]
            result = [np.min(x_coords), np.min(y_coords), np.max(x_coords), np.max(y_coords)]
        else:
            # Fallback - convert to numpy and try again
            bbox_array = np.array(bbox)
            if bbox_array.shape == (4, 2):
                x_coords = bbox_array[:, 0]
                y_coords = bbox_array[:, 1]
                result = [np.min(x_coords), np.min(y_coords), np.max(x_coords), np.max(y_coords)]
            elif len(bbox_array) == 8:
                # Format: [x1,y1,x2,y2,x3,y3,x4,y4]
                result = points_to_bbox(bbox_array)
            else:
                result = [0, 0, 100, 100]  # Default fallback
        
        # ƒê·∫£m b·∫£o t·∫•t c·∫£ gi√° tr·ªã l√† integers v√† >= 0
        result = [max(0, int(x)) for x in result]
        return result
        
    except Exception:
        return [0, 0, 100, 100]  # Safe fallback

def sort_texts_with_xycut(texts_with_info):
    """
    S·∫Øp x·∫øp text theo th·ª© t·ª± ƒë·ªçc s·ª≠ d·ª•ng XY-Cut algorithm
    
    Args:
        texts_with_info: List of dicts v·ªõi keys: 'text', 'score', 'bbox'
    
    Returns:
        List texts ƒë√£ s·∫Øp x·∫øp theo th·ª© t·ª± ƒë·ªçc
    """
    if not texts_with_info:
        return []
    
    # Chu·∫©n b·ªã d·ªØ li·ªáu cho XY-Cut
    boxes = []
    indices = list(range(len(texts_with_info)))
    
    for i, text_info in enumerate(texts_with_info):
        bbox = text_info.get('bbox', [[0, 0], [0, 0], [0, 0], [0, 0]])
        # Chuy·ªÉn v·ªÅ format [x_min, y_min, x_max, y_max]
        converted_bbox = convert_bbox_to_xycut_format(bbox)
        boxes.append(converted_bbox)
    
    boxes = np.array(boxes, dtype=np.int32)
    indices = np.array(indices, dtype=np.int32)
    
    # Ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o
    if len(boxes) == 0:
        return []
    
    try:
        # Ch·∫°y XY-Cut ƒë·ªÉ l·∫•y th·ª© t·ª± ƒë·ªçc
        reading_order = []
        recursive_xy_cut(boxes, indices, reading_order)
        
        # S·∫Øp x·∫øp texts theo th·ª© t·ª± ƒë·ªçc
        if reading_order:
            sorted_texts = [texts_with_info[i] for i in reading_order]
        else:
            # Fallback v·ªÅ s·∫Øp x·∫øp ƒë∆°n gi·∫£n n·∫øu XY-Cut kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£
            sorted_texts = sort_texts_by_position_fallback(texts_with_info)
            
    except Exception:
        # Fallback v·ªÅ s·∫Øp x·∫øp ƒë∆°n gi·∫£n n·∫øu XY-Cut th·∫•t b·∫°i
        sorted_texts = sort_texts_by_position_fallback(texts_with_info)
    
    return sorted_texts

def sort_texts_by_position_fallback(texts_with_info):
    """S·∫Øp x·∫øp text theo v·ªã tr√≠ t·ª´ tr√™n xu·ªëng d∆∞·ªõi, tr√°i sang ph·∫£i (fallback method)"""
    def get_sort_key(text_info):
        bbox = text_info.get('bbox', [[0, 0], [0, 0], [0, 0], [0, 0]])
        try:
            # T√≠nh t·ªça ƒë·ªô trung t√¢m
            if isinstance(bbox[0], list):
                x_coords = [point[0] for point in bbox]
                y_coords = [point[1] for point in bbox]
                center_x = sum(x_coords) / len(x_coords)
                center_y = sum(y_coords) / len(y_coords)
            else:
                # Fallback
                center_x, center_y = 0, 0
            return (center_y, center_x)
        except:
            return (0, 0)
    
    return sorted(texts_with_info, key=get_sort_key)

def get_text(image_input, save_output: bool = False, output_name: str = "output", sort_by_reading_order: bool = True) -> str:
    """
    Ch·∫°y OCR tr√™n m·ªôt ·∫£nh v·ªõi t√≠nh nƒÉng s·∫Øp x·∫øp text theo th·ª© t·ª± ƒë·ªçc s·ª≠ d·ª•ng XY-Cut.

    Args:
        image_input (str or np.ndarray): ƒê∆∞·ªùng d·∫´n ·∫£nh ho·∫∑c ·∫£nh numpy array (BGR).
        save_output (bool): N·∫øu True, l∆∞u ·∫£nh k·∫øt qu·∫£ v√† JSON.
        output_name (str): T√™n c∆° s·ªü ƒë·ªÉ l∆∞u ·∫£nh/JSON n·∫øu c·∫ßn.
        sort_by_reading_order (bool): N·∫øu True, s·∫Øp x·∫øp text theo th·ª© t·ª± ƒë·ªçc b·∫±ng XY-Cut.

    Returns:
        str: VƒÉn b·∫£n ƒë√£ nh·∫≠n d·∫°ng t·ª´ ·∫£nh, ƒë√£ s·∫Øp x·∫øp theo th·ª© t·ª± ƒë·ªçc.
    """
    ocr = get_ocr_instance()

    # Ki·ªÉm tra ƒë·∫ßu v√†o l√† path hay array
    if isinstance(image_input, str):
        if not os.path.exists(image_input):
            raise FileNotFoundError(f"·∫¢nh kh√¥ng t·ªìn t·∫°i: {image_input}")
        input_data = image_input
    elif isinstance(image_input, np.ndarray):
        input_data = image_input
    else:
        raise TypeError("image_input ph·∫£i l√† ƒë∆∞·ªùng d·∫´n (str) ho·∫∑c ·∫£nh numpy array (np.ndarray)")

    # G·ªçi OCR
    result = ocr.predict(input=input_data)

    all_texts_with_info = []

    for i, res in enumerate(result):
        angle = res.get("doc_preprocessor_res", {}).get("angle", None)
        
        texts = res.get("rec_texts", [])
        scores = res.get("rec_scores", [])
        boxes = res.get("dt_polys", [])

        # T·∫°o list c√°c text v·ªõi th√¥ng tin ƒë·∫ßy ƒë·ªß
        for text, score, box in zip(texts, scores, boxes):
            text_info = {
                'text': text,
                'score': float(score),
                'bbox': box.tolist() if hasattr(box, 'tolist') else box
            }
            all_texts_with_info.append(text_info)

    # S·∫Øp x·∫øp text theo th·ª© t·ª± ƒë·ªçc n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
    if sort_by_reading_order and all_texts_with_info:
        sorted_texts_info = sort_texts_with_xycut(all_texts_with_info)
        # Extract ch·ªâ text ƒë√£ ƒë∆∞·ª£c s·∫Øp x·∫øp
        all_texts = [info['text'] for info in sorted_texts_info]
    else:
        # Kh√¥ng s·∫Øp x·∫øp, gi·ªØ nguy√™n th·ª© t·ª± ban ƒë·∫ßu
        all_texts = [info['text'] for info in all_texts_with_info]

    return " ".join(all_texts)

def get_text_with_details(image_input, sort_by_reading_order: bool = True) -> dict:
    """
    Ch·∫°y OCR v√† tr·∫£ v·ªÅ th√¥ng tin chi ti·∫øt bao g·ªìm text, scores, bboxes ƒë√£ s·∫Øp x·∫øp theo XY-Cut.
    
    Args:
        image_input (str or np.ndarray): ƒê∆∞·ªùng d·∫´n ·∫£nh ho·∫∑c ·∫£nh numpy array (BGR).
        sort_by_reading_order (bool): N·∫øu True, s·∫Øp x·∫øp text theo th·ª© t·ª± ƒë·ªçc b·∫±ng XY-Cut.
    
    Returns:
        dict: {
            'texts': List[str],           # Danh s√°ch text ƒë√£ s·∫Øp x·∫øp
            'text_infos': List[dict],     # Th√¥ng tin chi ti·∫øt t·ª´ng text
            'combined_text': str          # Text ƒë∆∞·ª£c n·ªëi l·∫°i th√†nh chu·ªói
        }
    """
    ocr = get_ocr_instance()

    # Ki·ªÉm tra ƒë·∫ßu v√†o
    if isinstance(image_input, str):
        if not os.path.exists(image_input):
            raise FileNotFoundError(f"·∫¢nh kh√¥ng t·ªìn t·∫°i: {image_input}")
        input_data = image_input
    elif isinstance(image_input, np.ndarray):
        input_data = image_input
    else:
        raise TypeError("image_input ph·∫£i l√† ƒë∆∞·ªùng d·∫´n (str) ho·∫∑c ·∫£nh numpy array (np.ndarray)")

    # G·ªçi OCR
    result = ocr.predict(input=input_data)

    all_texts_with_info = []

    for i, res in enumerate(result):
        texts = res.get("rec_texts", [])
        scores = res.get("rec_scores", [])
        boxes = res.get("dt_polys", [])

        for text, score, box in zip(texts, scores, boxes):
            text_info = {
                'text': text,
                'confidence': float(score),
                'bbox': box.tolist() if hasattr(box, 'tolist') else box
            }
            all_texts_with_info.append(text_info)

    # S·∫Øp x·∫øp text theo th·ª© t·ª± ƒë·ªçc
    if sort_by_reading_order and all_texts_with_info:
        sorted_texts_info = sort_texts_with_xycut(all_texts_with_info)
    else:
        sorted_texts_info = all_texts_with_info

    # Tr·∫£ v·ªÅ k·∫øt qu·∫£
    texts = [info['text'] for info in sorted_texts_info]
    combined_text = " ".join(texts)

    return {
        'texts': texts,
        'text_infos': sorted_texts_info,
        'combined_text': combined_text
    }

def create_text_mask(image_shape, dt_polys):
    """T·∫°o mask t·ª´ c√°c bounding box text detection"""
    mask_uint8 = np.zeros((image_shape[0], image_shape[1]), dtype=np.uint8)
    
    for poly in dt_polys:
        poly_int = np.array(poly, dtype=np.int32)
        cv2.fillPoly(mask_uint8, [poly_int], 255)
    
    mask = mask_uint8 > 0
    return mask

def preprocess_non_text_areas(img, text_mask):
    """√Åp d·ª•ng ti·ªÅn x·ª≠ l√Ω ch·ªâ tr√™n v√πng kh√¥ng c√≥ text"""
    b, g, r = cv2.split(img)
    color_diff = np.abs(r - g) + np.abs(g - b) + np.abs(b - r)
    gray_mask = (color_diff < 30) & (r < 200) & (g < 200) & (b < 200)
    preprocessing_mask = gray_mask & (~text_mask)
    
    output = np.ones_like(img) * 255
    output[text_mask] = img[text_mask]
    output[preprocessing_mask] = img[preprocessing_mask]
    
    return output

def run_det_rec_preprocess(image_input, ocr_model=None):
    """
    H√†m ch√≠nh: X·ª≠ l√Ω ·∫£nh v·ªõi OCR v√† s·∫Øp x·∫øp text theo XY-Cut
    
    Args:
        image_input (str or np.ndarray): ƒê∆∞·ªùng d·∫´n ·∫£nh ho·∫∑c numpy array ·∫£nh
        ocr_model: OCR model (deprecated - s·∫Ω s·ª≠ d·ª•ng global instance)
    
    Returns:
        tuple: (processed_image, recognized_texts, detection_boxes)
    """
    # S·ª≠ d·ª•ng global OCR instance thay v√¨ parameter
    ocr = get_ocr_instance()
    
    # Ki·ªÉm tra ƒë·∫ßu v√†o l√† path hay numpy array
    if isinstance(image_input, str):
        # Input l√† ƒë∆∞·ªùng d·∫´n file
        if not os.path.exists(image_input):
            raise FileNotFoundError(f"Kh√¥ng th·ªÉ t√¨m th·∫•y file: {image_input}")
        img = cv2.imread(image_input)
        if img is None:
            raise ValueError(f"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {image_input}")
        input_data = image_input
    elif isinstance(image_input, np.ndarray):
        # Input l√† numpy array
        img = image_input.copy()
        input_data = image_input
    else:
        raise TypeError("image_input ph·∫£i l√† ƒë∆∞·ªùng d·∫´n (str) ho·∫∑c ·∫£nh numpy array (np.ndarray)")
    
    # Ch·∫°y OCR
    result = ocr.predict(input=input_data)
    
    all_texts_with_info = []
    all_boxes = []
    
    for res in result:
        texts = res.get("rec_texts", [])
        scores = res.get("rec_scores", [])
        boxes = res.get("dt_polys", [])
        
        # T·∫°o danh s√°ch text v·ªõi confidence scores
        for text, score, box in zip(texts, scores, boxes):
            text_info = {
                'text': text,
                'confidence': float(score),
                'bbox': box.tolist() if hasattr(box, 'tolist') else box
            }
            all_texts_with_info.append(text_info)
        
        all_boxes.extend(boxes)
        
        # X·ª≠ l√Ω ·∫£nh
        if len(boxes) > 0:
            text_mask = create_text_mask(img.shape, boxes)
            processed_image = preprocess_non_text_areas(img, text_mask)
        else:
            processed_image = img.copy()
    
    # S·∫Øp x·∫øp text b·∫±ng XY-Cut
    if all_texts_with_info:
        sorted_texts = sort_texts_with_xycut(all_texts_with_info)
    else:
        sorted_texts = all_texts_with_info
    
    return processed_image, sorted_texts, all_boxes

def save_results(processed_image, texts, image_path, output_dir="./output/"):
    """L∆∞u k·∫øt qu·∫£ (ch·ªâ ƒë·ªÉ test)"""
    os.makedirs(output_dir, exist_ok=True)
    
    base_name = os.path.splitext(os.path.basename(image_path))[0]
    
    # L∆∞u ·∫£nh
    processed_path = os.path.join(output_dir, f"{base_name}_processed.jpg")
    cv2.imwrite(processed_path, processed_image)
    
    # L∆∞u text
    ocr_result_path = os.path.join(output_dir, f"{base_name}_ocr_result.json")
    with open(ocr_result_path, 'w', encoding='utf-8') as f:
        json.dump(texts, f, ensure_ascii=False, indent=2)
    
    print(f"ƒê√£ l∆∞u: {processed_path}")
    print(f"ƒê√£ l∆∞u: {ocr_result_path}")

# C√ÅCH TEST:
# 1. Test v·ªõi h√†m m·ªõi (OCR + XY-Cut sorting):
#    text = get_text("./anh_test/1.jpg", sort_by_reading_order=True)
#    print("Text nh·∫≠n d·∫°ng (ƒë√£ s·∫Øp x·∫øp):", text)
#
# 2. Test v·ªõi h√†m chi ti·∫øt:
#    result = get_text_with_details("./anh_test/1.jpg")
#    print("Texts sorted:", result['texts'])
#    print("Combined:", result['combined_text'])
#
# 3. Test v·ªõi numpy array:
#    img = cv2.imread("./anh_test/1.jpg")
#    cropped = img[100:300, 50:400]
#    text = get_text(cropped, sort_by_reading_order=True)
#    print("Text t·ª´ v√πng c·∫Øt (ƒë√£ s·∫Øp x·∫øp):", text)
#
# 4. So s√°nh v·ªõi/kh√¥ng XY-Cut:
#    text_sorted = get_text("./anh_test/1.jpg", sort_by_reading_order=True)
#    text_original = get_text("./anh_test/1.jpg", sort_by_reading_order=False)
#    print("V·ªõi XY-Cut:", text_sorted)
#    print("Kh√¥ng XY-Cut:", text_original)

if __name__ == "__main__":
    print("=== TEST H√ÄML M·ªöI: get_text v·ªõi XY-Cut ===")
    image_path = "./anh_test/1.jpg"
    
    # Test v·ªõi file ·∫£nh
    if os.path.exists(image_path):
        print("\n1Ô∏è‚É£ Test OCR v·ªõi XY-Cut sorting:")
        text_result = get_text(image_path, sort_by_reading_order=True)
        print(f"Text nh·∫≠n d·∫°ng (s·∫Øp x·∫øp XY-Cut): {text_result}")
        
        print("\n2Ô∏è‚É£ Test OCR kh√¥ng sorting:")
        text_no_sort = get_text(image_path, sort_by_reading_order=False)
        print(f"Text nh·∫≠n d·∫°ng (kh√¥ng s·∫Øp x·∫øp): {text_no_sort}")
        
        print("\n3Ô∏è‚É£ Test chi ti·∫øt v·ªõi XY-Cut:")
        detailed_result = get_text_with_details(image_path)
        print(f"S·ªë text regions: {len(detailed_result['text_infos'])}")
        print(f"Texts ri√™ng l·∫ª: {detailed_result['texts']}")
        print(f"Combined text: {detailed_result['combined_text']}")
        
        # Test v·ªõi numpy array (c·∫Øt ·∫£nh)
        print("\n4Ô∏è‚É£ Test v·ªõi numpy array (cropped image):")
        img = cv2.imread(image_path)
        if img is not None:
            cropped_img = img[100:300, 50:400]  # C·∫Øt m·ªôt v√πng
            text_from_crop = get_text(cropped_img, sort_by_reading_order=True)
            print(f"Text t·ª´ v√πng c·∫Øt (v·ªõi XY-Cut): {text_from_crop}")
    else:
        print(f"File {image_path} kh√¥ng t·ªìn t·∫°i. T·∫°o file test ho·∫∑c thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n.")
    
    print("\n=== TEST H√ÄM C≈®: run_det_rec_preprocess v·ªõi XY-Cut ===")
    # Test h√†m c≈© ƒë·ªÉ ƒë·∫£m b·∫£o t∆∞∆°ng th√≠ch ng∆∞·ª£c
    if os.path.exists(image_path):
        processed_img, texts, boxes = run_det_rec_preprocess(image_path)
        print(f"K√≠ch th∆∞·ªõc ·∫£nh x·ª≠ l√Ω: {processed_img.shape}")
        print(f"S·ªë text t√¨m ƒë∆∞·ª£c: {len(texts)}")
        for i, text in enumerate(texts[:5]):  # Hi·ªÉn th·ªã 5 text ƒë·∫ßu
            print(f"Text {i+1}: '{text['text']}' (confidence: {text['confidence']:.3f})")
        
        # L∆∞u k·∫øt qu·∫£ ƒë·ªÉ test
        save_results(processed_img, texts, image_path)
        
        print(f"\nüìù Text ƒë∆∞·ª£c s·∫Øp x·∫øp theo XY-Cut:")
        sorted_text_string = " ".join([t['text'] for t in texts])
        print(sorted_text_string)